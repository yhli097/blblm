<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Yahui Li" />

<meta name="date" content="2020-06-10" />

<title>Final Project: Linear Regression with Little Bag of Bootstraps by Parallel and Rcpp</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Final Project: Linear Regression with Little Bag of Bootstraps by Parallel and Rcpp</h1>
<h4 class="author">Yahui Li</h4>
<h4 class="date">June 10, 2020</h4>



<p>This vignette is a report of final project in STA141C, 2020 Spring. Our goal is to implement the little bag of bootstrap in linear regression to get the estimation and confidence interval of coefficients, sigma and prediction. At the same time, make use of multiple ways for high performance statistical computing, such as parallel computing, distribution and Rcpp.</p>
<div id="overview" class="section level3">
<h3>Overview</h3>
<p>The main function to make the little bag of bootstrap of linear regression on the data set is <code>blblm()</code>. The input has formula, data, files, number of subsamples <span class="math inline">\(m\)</span>, number of bootstrap times <span class="math inline">\(B\)</span>, the cluster (default as <code>NULL</code>, no parallel), method (can be input as ‘lm’, ‘lmR’, ‘lmC’). The output will be a list including original formula and the estimate coefficient and sigma from weighted linear regression for each little bag of bootstrap in each subsample.</p>
<p>To get a high computing performance, the users can use cluster in parallel package for parallel computing. Also, given split data, the users can input the path of these data and distribute them into separate workers if they already establish multiple cores. For calculation of the basic function <code>lm1()</code>, if the method is ‘lm’, it will use <code>lm()</code> function in R directly. If the method is ‘lmR’, it will calculate the estimate coefficient and sigma on base R calculation. However, if the method is ‘lmC’, it will call a written Rcpp function <code>lmC()</code> which will calculate estimations by C++ method.</p>
<p>With the result of <code>blblm()</code>, we can take advantage to calculate the the estimation coefficient, sigma and prediction as well as their confidence interval by bootstrap method. I define <code>coef()</code> to get the estimated coefficient; <code>confint()</code> to get it’s confidence interval; <code>sigma()</code> to get the estimated sigma, with choice of <code>confidence = TRUE</code> to get the confidence interval as well; <code>predict()</code> to get the estimated prediction given a new data, with choice of <code>confidence = TRUE</code> to get the confidence interval as well. In order to make use of cluster, I also provide the choice to use cluster in these export functions.</p>
<p>Now I will use some data set and make multiple choice to compare the computing performance.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" title="1"><span class="kw">library</span>(blblm)</a>
<a class="sourceLine" id="cb1-2" title="2"><span class="kw">library</span>(parallel)</a></code></pre></div>
</div>
<div id="parallelization" class="section level3">
<h3>Parallelization</h3>
<p>For a given data <code>mtcars</code> in base R, I use little bootstrap method to for the linear regression <code>mpg ~ wt * hp</code>. In order to use parallel, I create a cluster firstly.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" title="1"><span class="co"># make a cluster</span></a>
<a class="sourceLine" id="cb2-2" title="2">cl =<span class="st"> </span><span class="kw">makeCluster</span>(<span class="dv">2</span>) </a></code></pre></div>
<p>Then I compare the running time of this process without or with parallelization.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" title="1">bench<span class="op">::</span><span class="kw">mark</span>(</a>
<a class="sourceLine" id="cb3-2" title="2">  <span class="dt">fit_no =</span> <span class="kw">blblm</span>(mpg <span class="op">~</span><span class="st"> </span>wt <span class="op">*</span><span class="st"> </span>hp, <span class="dt">data =</span> mtcars, <span class="dt">m =</span> <span class="dv">4</span>,<span class="dt">B =</span> <span class="dv">200</span>),</a>
<a class="sourceLine" id="cb3-3" title="3">  <span class="dt">fit_cl =</span> <span class="kw">blblm</span>(mpg <span class="op">~</span><span class="st"> </span>wt <span class="op">*</span><span class="st"> </span>hp, <span class="dt">data =</span> mtcars, <span class="dt">m =</span> <span class="dv">4</span>,<span class="dt">B =</span> <span class="dv">200</span>, <span class="dt">cluster =</span> cl),</a>
<a class="sourceLine" id="cb3-4" title="4">  <span class="dt">check =</span> <span class="ot">FALSE</span>,</a>
<a class="sourceLine" id="cb3-5" title="5">  <span class="dt">relative =</span> <span class="ot">TRUE</span></a>
<a class="sourceLine" id="cb3-6" title="6">)</a>
<a class="sourceLine" id="cb3-7" title="7"><span class="co">#&gt; # A tibble: 2 x 6</span></a>
<a class="sourceLine" id="cb3-8" title="8"><span class="co">#&gt;   expression   min median `itr/sec` mem_alloc `gc/sec`</span></a>
<a class="sourceLine" id="cb3-9" title="9"><span class="co">#&gt;   &lt;bch:expr&gt; &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb3-10" title="10"><span class="co">#&gt; 1 fit_no      1.02   1.02      1         16.6      Inf</span></a>
<a class="sourceLine" id="cb3-11" title="11"><span class="co">#&gt; 2 fit_cl      1      1         1.02       1        NaN</span></a></code></pre></div>
<p>The result shows the <code>blblm()</code> with parallelization is about twice faster than without it. However, the time is not the quarter of the time without cluster even we set four cores and split data into four parts. The reason can be that the assignment will consume time and running four GPUs will not have a good performance. Also, the size of the data and test time is not too large so the difference is not so clear. On the other hand, the allocated memory for parallel is much less than without it, which is also an improvement.</p>
</div>
<div id="distribution" class="section level3">
<h3>Distribution</h3>
<p>If the input data is the whole data set, first of all, it will be divided into several sub-data randomly and evenly. Besides, I provide the choice for the users to input a set of file paths, where the data has already split into several files. Moreover, if users also input the clusters from parallel package, each file will be distributed into a worker automatically, which will minimize memory usage.</p>
<p>In order to get a satisfied result, we create <span class="math inline">\(100\)</span> files, and each of them contains <span class="math inline">\(100\)</span> cases of x and y. We save them in the “files” folder.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" title="1">file_names &lt;-<span class="st"> </span><span class="kw">file.path</span>(<span class="st">&quot;files&quot;</span>, <span class="kw">list.files</span>(<span class="st">&quot;files&quot;</span>))</a>
<a class="sourceLine" id="cb4-2" title="2">bench<span class="op">::</span><span class="kw">mark</span>(</a>
<a class="sourceLine" id="cb4-3" title="3">    <span class="dt">fit_no =</span> <span class="kw">blblm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">files =</span> file_names, <span class="dt">B =</span> <span class="dv">100</span>),</a>
<a class="sourceLine" id="cb4-4" title="4">    <span class="dt">fit_cl =</span> <span class="kw">blblm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">files =</span> file_names, <span class="dt">B =</span> <span class="dv">100</span>, <span class="dt">cluster =</span> cl),</a>
<a class="sourceLine" id="cb4-5" title="5">  <span class="dt">check =</span> <span class="ot">FALSE</span>, <span class="dt">relative =</span> <span class="ot">TRUE</span></a>
<a class="sourceLine" id="cb4-6" title="6">)</a>
<a class="sourceLine" id="cb4-7" title="7"><span class="co">#&gt; # A tibble: 2 x 6</span></a>
<a class="sourceLine" id="cb4-8" title="8"><span class="co">#&gt;   expression   min median `itr/sec` mem_alloc `gc/sec`</span></a>
<a class="sourceLine" id="cb4-9" title="9"><span class="co">#&gt;   &lt;bch:expr&gt; &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb4-10" title="10"><span class="co">#&gt; 1 fit_no      1.84   1.84      1        1138.      Inf</span></a>
<a class="sourceLine" id="cb4-11" title="11"><span class="co">#&gt; 2 fit_cl      1      1         1.84        1       NaN</span></a></code></pre></div>
<p>From the result, the distribution can be three time faster by the cluster, at the same time, it saves much memory space as we can expect. Thus, when we deal with many files, the distribution method can make a great promotion on both time and space.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" title="1">fit =<span class="st"> </span><span class="kw">blblm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">files =</span> file_names, <span class="dt">B =</span> <span class="dv">100</span>, <span class="dt">cluster =</span> cl)</a>
<a class="sourceLine" id="cb5-2" title="2"></a>
<a class="sourceLine" id="cb5-3" title="3">bench<span class="op">::</span><span class="kw">mark</span>(</a>
<a class="sourceLine" id="cb5-4" title="4">  <span class="dt">conf_no =</span> <span class="kw">confint</span>(fit), <span class="dt">conf_cl =</span> <span class="kw">confint</span>(fit, <span class="dt">cluster =</span> cl),<span class="dt">relative =</span> <span class="ot">TRUE</span> </a>
<a class="sourceLine" id="cb5-5" title="5">)</a>
<a class="sourceLine" id="cb5-6" title="6"><span class="co">#&gt; # A tibble: 2 x 6</span></a>
<a class="sourceLine" id="cb5-7" title="7"><span class="co">#&gt;   expression   min median `itr/sec` mem_alloc `gc/sec`</span></a>
<a class="sourceLine" id="cb5-8" title="8"><span class="co">#&gt;   &lt;bch:expr&gt; &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb5-9" title="9"><span class="co">#&gt; 1 conf_no     1      1         3.57      5.54      Inf</span></a>
<a class="sourceLine" id="cb5-10" title="10"><span class="co">#&gt; 2 conf_cl     1.40   3.66      1         1         NaN</span></a>
<a class="sourceLine" id="cb5-11" title="11">bench<span class="op">::</span><span class="kw">mark</span>(</a>
<a class="sourceLine" id="cb5-12" title="12">  <span class="dt">sigma_no =</span> <span class="kw">sigma</span>(fit,<span class="dt">confidence =</span> <span class="ot">TRUE</span>), </a>
<a class="sourceLine" id="cb5-13" title="13">  <span class="dt">sigma_cl =</span> <span class="kw">sigma</span>(fit,<span class="dt">confidence =</span> <span class="ot">TRUE</span>, <span class="dt">cluster =</span> cl), </a>
<a class="sourceLine" id="cb5-14" title="14">  <span class="dt">relative =</span> <span class="ot">TRUE</span> </a>
<a class="sourceLine" id="cb5-15" title="15">)</a>
<a class="sourceLine" id="cb5-16" title="16"><span class="co">#&gt; # A tibble: 2 x 6</span></a>
<a class="sourceLine" id="cb5-17" title="17"><span class="co">#&gt;   expression   min median `itr/sec` mem_alloc `gc/sec`</span></a>
<a class="sourceLine" id="cb5-18" title="18"><span class="co">#&gt;   &lt;bch:expr&gt; &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb5-19" title="19"><span class="co">#&gt; 1 sigma_no     1      1        11.6      2.43      Inf</span></a>
<a class="sourceLine" id="cb5-20" title="20"><span class="co">#&gt; 2 sigma_cl    11.6   11.6       1        1         NaN</span></a>
<a class="sourceLine" id="cb5-21" title="21">bench<span class="op">::</span><span class="kw">mark</span>(</a>
<a class="sourceLine" id="cb5-22" title="22">  <span class="dt">pred_no =</span> <span class="kw">predict</span>(fit, <span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>)), <span class="dt">confidence =</span> <span class="ot">TRUE</span>),</a>
<a class="sourceLine" id="cb5-23" title="23">  <span class="dt">pred_cl =</span> <span class="kw">predict</span>(fit, <span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>)), <span class="dt">confidence =</span> <span class="ot">TRUE</span>, <span class="dt">cluster =</span> cl), </a>
<a class="sourceLine" id="cb5-24" title="24">  <span class="dt">relative =</span> <span class="ot">TRUE</span> </a>
<a class="sourceLine" id="cb5-25" title="25">)</a>
<a class="sourceLine" id="cb5-26" title="26"><span class="co">#&gt; # A tibble: 2 x 6</span></a>
<a class="sourceLine" id="cb5-27" title="27"><span class="co">#&gt;   expression   min median `itr/sec` mem_alloc `gc/sec`</span></a>
<a class="sourceLine" id="cb5-28" title="28"><span class="co">#&gt;   &lt;bch:expr&gt; &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb5-29" title="29"><span class="co">#&gt; 1 pred_no     1      1         3.47      502.      Inf</span></a>
<a class="sourceLine" id="cb5-30" title="30"><span class="co">#&gt; 2 pred_cl     3.52   3.47      1           1       NaN</span></a></code></pre></div>
<p>From the result the parallelization has little help for time on the export functions <code>confint()</code>, <code>sigma()</code>, <code>predict()</code>. The reason can be that the number of subsamples is too small to make parallel computation, since running four GPUs also cost time. However, if we focus more on the memory, we can still choose cluster, which has an obvious reduction on allocated memory.</p>
</div>
<div id="rcpp" class="section level3">
<h3>Rcpp</h3>
<p>In original <code>blblm()</code>, we call <code>lm()</code> function in R to get the estimate coefficient and sigma for each bootstrap. However, it is a waste since <code>lm()</code> will calculate many other statistics. In order to reduce the computation, we add two more method, “lmR” and “lmC”, and the original method is defaulted as “lm”. “lmR” will use base R function to calculate the estimate coefficient and sigma by <span class="math display">\[\hat\beta = (X^\top X)^{-1}X^\top Y \text{ and } 
\hat\sigma^2 = \|Y-X\hat\beta\|_2^2/(n-p)\]</span> where <span class="math inline">\(X\)</span> is design matrix and <span class="math inline">\(Y\)</span> is response vector by formula. <span class="math inline">\(n\)</span> is the size of whole data and <span class="math inline">\(p\)</span> is the rank of <span class="math inline">\(X\)</span>. Furthermore, it can still be improved by written in C++ code. Here we use RcppArmadillo package to make linear algebra computation.</p>
<p>We split mtcars data into <span class="math inline">\(4\)</span> parts and use cluster to make parallelization. Then we compare three different methods when computing estimations of weighted linear regression. In order to get a obvious result, we run little bag of bootstrap <span class="math inline">\(5000\)</span> times.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" title="1">bench<span class="op">::</span><span class="kw">mark</span>(</a>
<a class="sourceLine" id="cb6-2" title="2">  <span class="dt">fit_lm =</span> <span class="kw">blblm</span>(mpg <span class="op">~</span><span class="st"> </span>wt <span class="op">*</span><span class="st"> </span>hp, <span class="dt">data =</span> mtcars, <span class="dt">m =</span> <span class="dv">4</span>,<span class="dt">B =</span> <span class="dv">5000</span>, <span class="dt">cluster =</span> cl),</a>
<a class="sourceLine" id="cb6-3" title="3">  <span class="dt">fit_lmR =</span> <span class="kw">blblm</span>(mpg <span class="op">~</span><span class="st"> </span>wt <span class="op">*</span><span class="st"> </span>hp, <span class="dt">data =</span> mtcars, <span class="dt">m =</span> <span class="dv">4</span>,<span class="dt">B =</span> <span class="dv">5000</span>, <span class="dt">cluster =</span> cl,<span class="dt">method =</span> <span class="st">&quot;lmR&quot;</span>),</a>
<a class="sourceLine" id="cb6-4" title="4">  <span class="dt">fit_lmC =</span> <span class="kw">blblm</span>(mpg <span class="op">~</span><span class="st"> </span>wt <span class="op">*</span><span class="st"> </span>hp, <span class="dt">data =</span> mtcars, <span class="dt">m =</span> <span class="dv">4</span>,<span class="dt">B =</span> <span class="dv">5000</span>, <span class="dt">cluster =</span> cl,<span class="dt">method =</span> <span class="st">&quot;lmC&quot;</span>),</a>
<a class="sourceLine" id="cb6-5" title="5">  <span class="dt">check =</span> <span class="ot">FALSE</span>, <span class="dt">relative =</span> <span class="ot">TRUE</span></a>
<a class="sourceLine" id="cb6-6" title="6">)</a>
<a class="sourceLine" id="cb6-7" title="7"><span class="co">#&gt; # A tibble: 3 x 6</span></a>
<a class="sourceLine" id="cb6-8" title="8"><span class="co">#&gt;   expression   min median `itr/sec` mem_alloc `gc/sec`</span></a>
<a class="sourceLine" id="cb6-9" title="9"><span class="co">#&gt;   &lt;bch:expr&gt; &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb6-10" title="10"><span class="co">#&gt; 1 fit_lm      1.19   1.19      1            1      NaN</span></a>
<a class="sourceLine" id="cb6-11" title="11"><span class="co">#&gt; 2 fit_lmR     1      1         1.19         1      NaN</span></a>
<a class="sourceLine" id="cb6-12" title="12"><span class="co">#&gt; 3 fit_lmC     1.00   1.00      1.19         1      NaN</span></a></code></pre></div>
<p>The result shows that Rcpp method “lmC” is faster than R method “lmR”, which is faster than <code>lm</code> method. Actually we successfully run parallel as well as Rcpp file at the same time and it gets a great result.</p>
</div>
<div id="conclusion" class="section level3">
<h3>Conclusion</h3>
<p>Let’s look back at the <span class="math inline">\(100\)</span> subsamples in files. Now we choose cluster to do distribution or no cluster, and three different methods to calculate estimations.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" title="1">results &lt;-<span class="st"> </span>bench<span class="op">::</span><span class="kw">press</span>(</a>
<a class="sourceLine" id="cb7-2" title="2">  <span class="dt">method =</span> <span class="kw">c</span>(<span class="st">&quot;lm&quot;</span>,<span class="st">&quot;lmR&quot;</span>,<span class="st">&quot;lmC&quot;</span>),</a>
<a class="sourceLine" id="cb7-3" title="3">  {</a>
<a class="sourceLine" id="cb7-4" title="4">    bench<span class="op">::</span><span class="kw">mark</span>(</a>
<a class="sourceLine" id="cb7-5" title="5">        <span class="dt">fit_no =</span> <span class="kw">blblm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">files =</span> file_names, <span class="dt">B =</span> <span class="dv">100</span>, <span class="dt">method =</span> method),</a>
<a class="sourceLine" id="cb7-6" title="6">        <span class="dt">fit_cl =</span> <span class="kw">blblm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">files =</span> file_names, <span class="dt">B =</span> <span class="dv">100</span>, <span class="dt">cluster =</span> cl, <span class="dt">method =</span> method),</a>
<a class="sourceLine" id="cb7-7" title="7">      <span class="dt">check =</span> <span class="ot">FALSE</span></a>
<a class="sourceLine" id="cb7-8" title="8">    )</a>
<a class="sourceLine" id="cb7-9" title="9">  }</a>
<a class="sourceLine" id="cb7-10" title="10">)</a>
<a class="sourceLine" id="cb7-11" title="11"><span class="co">#&gt; Running with:</span></a>
<a class="sourceLine" id="cb7-12" title="12"><span class="co">#&gt;   method</span></a>
<a class="sourceLine" id="cb7-13" title="13"><span class="co">#&gt; 1 lm</span></a>
<a class="sourceLine" id="cb7-14" title="14"><span class="co">#&gt; 2 lmR</span></a>
<a class="sourceLine" id="cb7-15" title="15"><span class="co">#&gt; 3 lmC</span></a>
<a class="sourceLine" id="cb7-16" title="16">ggplot2<span class="op">::</span><span class="kw">autoplot</span>(results,<span class="dt">type =</span> <span class="st">&quot;beeswarm&quot;</span>)</a></code></pre></div>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAqAAAAEgCAMAAABcujGyAAABO1BMVEUAAAAAADoAAGYAOpAAZrYAujgZGT8ZGWIZP2IZP4EZYp8aGhozMzM6AAA6ADo6AGY6OpA6kNs/GRk/GWI/P4E/gb1NTU1NTW5NTY5NbqtNjshhnP9iGRliGT9iGWJiPxliYhlin9lmAABmADpmAGZmZrZmtv9uTU1uTW5uTY5ubqtujo5uq+SBPxmBPz+BgWKBvdmOTU2OTW6OTY6OyP+QOgCQOjqQOmaQZgCQkGaQtpCQ2/+fYhmfvYGf2dmrbk2rbm6rbo6rjk2ryKur5P+2ZgC2Zma22/+2//+9gT+92dnIjk3I5KvI/8jI///Zn2LZvYHZ2Z/Z2b3Z2dnbkDrb2//b/7bb/9vb///kq27k5Kvk///r6+vy8vL4dm3/tmb/yI7/25D/27b/5Kv//7b//8j//9v//+T///+HxISIAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAPtElEQVR4nO2dDVsU1xmGV4W0lWgkqauWNG1Mi8VoGhNJW7WSNtBibfBr25ragnQF5v//gs6ZHWCBWd73fLw7H9zPpSy7zzU7z3O4d+bMsLP0MoQarF7dARA6TQCKGi0ARY0WgKJGC0BRowWgqNGKBPRVG9TGsHXH0CkOHpUAtGFqU1YATaM2hq07hk5x8KgEoA1Tm7ICaBq1MWzdMXSKg0clAG2Y2pQVQNOojWHrjqFTHDwqAWjD1KasAJpGbQxbdwyd4uBRqRGAPv/ocf7v2IMv73564MY9faqwfjGfzc3N/eRv3itJNbA+YZ9/mGed+5H/MMfBoxKA6uUV84n7eT/yJzTVwHoBWtx7EhzWUjUA+vKL387NXc03MFdfvXrxcf7CdV/++NEv5+Y+LR8obn78i09HA5d/HV/EX2Fh42K++PmXr8aA8A7ruVRc2IPHAsNaqg5A717MdyoXiwF5dPXVk+K75x9effUsfwk/OryZO3y1jy/ir7CwcTGfBezdx8N6LhUXli3o0cH84svif76RcduZF588Lsco/5/fKR7Pb8Z3R2OLBKwwLGxczGcXA4KOhfVcKi7saA4aPmG2VM2AfpwPzHtfHg6mu8m94iX9qDmA+sd8/tPpbkHjwubWs/cChjYOHpVqBvSTx+VwNXsL6h9z6nPQmLAFu084ij85mOX06HAwJ82X6gU0JOZ0j+LjwhaAujlpYFhL1Qxovj/Kdy0v7+ZHnKPBLI84X949dsRZL6AhMad6HjQubPnYh97nSOLgUakR50GN1cawdcfQKQ4elQC0YWpTVgBNozaGrTuGTnHwqASgDVObsgJoGrUxbN0xdIqDR6VIQP9TocoH481wu41hE8eJCjvZjYNHJQANXSGAAmgiu41hE8cBUG1bABVsk6wAqm4LoIJtkhVA1W0BVLBNsgKoui2ACrZJVgBVtwVQwTbJCqDqtgAq2CZZAVTdFkAF2yQrgKrbAqhgm2QFUHVbABVsk6wAqm4LoIJtkhVA1W0BVLBNsgKoui2ACrZJVgBVtwVQwTbJCqDqtgAq2CZZAVTdFkAF2yQrgKrbAqhgm2QFUHVbABVsk6wAqm4LoIJtkhVA1W0BVLBNsgKoui2ACrZJVgBVtwVQwTbJCqDqtgAq2CZZAVTdFkAF2yQrgKrbAqhgm2QFUHVbABVsk6wAqm4LoIJtkhVA1W0BVLBNsgKoui2ACrZJVgBVtwVQwTbJCqDqtgAq2CZZAVTdFkAF2yQrgKrbAqhgm2QFUHVbABVsk6wAqm4LoIJtkhVA1W0BVLBNsgKoui2ACrZJVgBVtwVQwTbJCqDqtgAq2CZZAVTdFkAF2yQrgKrbAqhgm2QFUHVbABVsk6wAqm4LoIJtkhVA1W0BVLBNsgKoui2ACrZJVgBVtwVQwTbJCqDqtgAq2CZZAVTdFkAF2yQrgKrbAqhgm2QFUHVbABVsk6wAqm4LoIJtkhVA1W0BVLBNsgKoui2ACrZJ1k4CurfS/3xpY7i0cdri3m0BVLBNsnYS0BGabQZ0YWFhZNQSdnZ2NmRpk6yRgE6skgTB0zUR0J17/WvfLX1/r3+9JHR4+8/9/v3CuH4ArXfbKQK6sFASWkvY2dlTCW0ToJOrGEE5rlO3oMPxXfzw1p3s7Y032dPRTZa9n2sKCYNVAFrb2oufam1rT6paq3gAmn+X/9/5eiPb+Wq1fND75cgWVFjaJOvZ2IKOAHU3e9+2AVDmoFq3lXPQ9m9BD40Whk0cp6NH8VWAHs5BnbzbAqhgm2TtMKB7KwdH8SWgrTmKPzRaGDZxnC4CqpJ3WwAVbJOsnQZ0eKvvdG21yvRuC6CCbZK104CeKu+2ACrYJlkBVN0WQAXbJCuAqtsCqGCbZJ0yoO9u9s49+GA9213u9WbiAAPQ4BUC6CRA392cz/+fX99dnslvF+MIA9DQFQLoJEC3zq9n2eD8+vblh3F0OQFo6AoBdBKggwuvs2z7g/UC1FgdAXT7Us/J43m92wKoYJtk7Qigbs7gKe+2ACrYJllr2MVvGeziAya03m0BVLBNstZ3kBSw0Tuqo1tQAE1knmlAi9NMfzhvcJrJf9Lg3RZABdsk65QBLVhyE9EEOrqL73GQlMY804BunXsYv2vfF6eZQlcIoBO3oINe/K59XwAaukIAPXUXn0pHAXXo9+Y9FvduC6CCbZK1K4AO3OzTnSRQy7stgAq2SdaOAFqeB/U5lvduC6CCbZIVQNVtAVSwTbJOF9D/VssXzZHYxYeuEECnDygHSalMALUB1FvebQFUsE2yAqi6LYAKtknWLgCaHyHxq85kJoCyBdXbbQybOA6AatsCqGCbZO0KoKPdvM977rzbAqhgm2TtCqBrM+5U6MDjjSjebQFUsE2ydgTQfAPq3sbHb5LiTQAttLm5mRhQ92skAI03AbTkc4zQ0t2+8vteb7F4e3wO2tF7AqC7y/PuzdBr7OKjTQCdDOil+eJ6kLXiZuxe9dTy+HXxM9maz8Uk3m0BVLC7D+gH6+7/u1+tZ+8+e7h/77OHmXtEANRf3m0BVLC7BGjlHLRE0t3sfnMAqPsd0bmqy+gBNHSFABp2FF+9Ba3cep4AlPOgqUwAlQDdn4MeuScBynnQVCaAioCWR/GH9yr38JwHDV4hgIYB6inOg4auEECnDijnQZOZAGoBKOdBk5kAagKov7zbAqhgm2QFUHVbABVsk6ydAXTQ6y0O2MXHmwBqAujahX+OzjSp5d0WQAXbJGtHAC1OMy1ymimBCaAAqrfbGDZxnG4Amg3cLp6PvklgAqjNQdIWH32TxgRQG0C95d0WQAXbJGtHAOXP0CQzAdToIMl3ce+2ACrYJlmbBKh7c91JlW+5O3kO/thBku/ftvFuC6CC3SlAZ2dn9YC6HfjJ9yLzd5JCVwigIqCzs+OEjgFavFl5+8prd1XSwRuX3WUfJ+nlICl0hQAaDmhxkXEOZ5ZDOrrg2F1GlwPrru4E0DR5ADQY0PIi40GO5nz5vfvr3RdkQIuPAPc5UvJuC6CC3SVAJ81By4uMt6/8q9jDF9+rtqD8EYVUJoCedhRfXmS8+82DK6/L71VzUP4MTTITQE89zVReZDxwv7U8uPx4d7nq428ANHSFABoOaHmR8fblh1n5ve48qLtkjl18ChNAJwLqqarzoB6nQr3bAqhgm2TtCKAB8m4LoIJtkrUjgO7+w3tx77YAKtgmWTsCaDn73P3dunpx77YAKtgmWTsCaLbljqK2+F18vAmgNnPQ4jDJ46LOVv3MWxU2cZyuAOo+/Mbnio9W/cxbFTZxnI4Aurvcm9mqOFk6Wd5tAVSwTbJ2BNB3N0cn6pmDRpsAagLor0e3f1lXL+7dFkAF2yRrRwANkHdbABVsk6ydAZQPD0tkAqgJoHx4WCoTQG0OkvhspkQmgE4EdPJlx9uXKi7nANDQFQKoDOjCwoIeUHe5R/EO0YmA8uFhyUwALfkcI3QM0MrLjrfc1HLt+CaUDw8LXSGAhgNaedmxM7nsOF0eAA0GtPqy46z4Q0jHnwxAQ1cIoMFz0OrLjquvNgLQ0BUCaPBRfPVlx/lRfMVHMgBo6AoBNPw0U+Vlx5V8AmjwCgE0HNDKy46Lj7U5cSIUQENXCKBhgHoKQENXCKAAmshuY9jEcQBU2xZABdskK4Cq2wKoYJtk7S6geyv9z5c2hksbRx49vO/dFkAFuwOAJpUA6AjFdIBubm4Gj1MiQI9G6BCgp41tVwHdude/9t3S9/f61zfGHlkNBnRz81RCpwHosQjdAfTUse0qoG5bORzfxe+t3M/e3vh3cf/9XJ5rKwYxIGVCNSCCjTpazBPQ47t8z5cjW1DRDhtYtqD792+/yZiDRqUR7MCBPaNz0NRbUI7iRdsk69kB1M1Bh0t/B1AALRx7qQDdW0l0FA+gom2StbuASvJuC6CCbZK1+4AOb/Wdrq0ee9y7LYAKtknW7gM6Sd5tAVSwTbICqLotgAq2SVYAVbcFUME2yQqg6rYAKtgmWQFU3RZABdskK4Cq2wKoYJtkBVB1WwAVbJOsAKpuC6CCbZIVQNVtAVSwTbICqLotgAq2SVYAVbcFUME2yQqg6rYAKtgmWQFU3RZABdskK4Cq2wKoYJtkBVB1WwAVbJOsAKpuC6CCbZIVQNVtAVSwTbICqLotgAq2SVYAVbcFUME2yQqg6rYAKtgmWQFU3RZABdskK4Cq2wKoYJtkBVB1WwAVbJOsAKpuC6CCbZIVQNVtAVSwTbICqLotgAq2SVYAVbcFUME2yQqg6rYAKtgmWQFU3RZABdskK4Cq2wKoYJtkBVB1WwAVbJOsAKpuC6CCbZIVQNVtAVSwTbICqLotgAq2SVYAVbcFUME2yQqg6rYAKtgmWQFU3RZABdskK4Cq2wKoYJtkBVB1WwAVbJOsAKpuC6CCbZIVQNVtAVSwTbICqLotgAq2SVYAVbcFUME2yQqg6rYAKtgmWQFU3RZABdskK4Cq2wKoYJtkBVB1WwAVbJOsAKpuC6CCbZIVQNVtAVSwTbICqLotgAq2SdazC2iV3q9hyeCl2xQ2Yo1RYeOaRgpAp7q6qKUBNI3a9DNvVVgATaM2/cxbFRZAEWqaABQ1WgCKGi0ARY0WgKJGKymgP/T7/esbgQv2+/fD1jpcyle5c69/4433OtsSNjhrVNjAgU2rpIA+DfypFXobOA5v3Y9ub+V+9sPPvJZrU9iorKFhQwc2rVICuvftanH7NuTlvvPVatCST699l7/Qd77eKF7w+idoU9iorKFhQwc2sVICmu8N3N7EdfJ/0bklwpZ04ze8/cb9IDyeoE1ho7KGhw0b2MRKCejwN6vuxV68Yn1VLBS05OgFfmM0jvonaFPYmKwRYcMGNrGSH8Xn06Xhrf413z6jeVLIkuMvdN8naFPYwKwRYSMGNp0sAM0C5uVP75Tf+M/oh2NTJc8naFPYwKwRYSMGNp1SAuoa7P1pw934lhkdBoQsORrHvZU7bo7k8QRtChuRNSZs2MAmVurzoG4/8NT/iK+c4wQsefR0nccTtClseNaYsIEDm1b8Jgk1WgCKGi0ARY0WgKJGC0BRowWgqNECUE/976/Z9uWHdac4OwJQPwHnlAWgfgLQKQtAvbR9qdebzyHdvvyg+C7/sphlu8u93vn1urN1UwDqJ7cFdYBeuvA6G/Tcl/Pru8szWTbIv0fpBaB+OgB00W1OF4sHttzW893NxbqzdVIA6qd9QN1UdP/LoFdovu5snRSA+qkSUPbudgJQP1UBunWOI3szAaif3FTzOKC7y/kmFEptBKCeWuvNHAe0OM0EnzYCUNRoAShqtAAUNVoAihotAEWNFoCiRgtAUaMFoKjRAlDUaAEoarT+D7DXPvGHPYPyAAAAAElFTkSuQmCC" /><!-- --></p>
<p>The plot shows that the cluster can significantly reduce the time, also, the method “lmC” is faster than “lmR”, and is faster than “lm”.</p>
<p>In conclusion, when the number of subsamples is large, we can use parallelization and distribution to save the running time as well as minimize memory usage. While the time of bootstrap is huge, we can use Rcpp function to implement calculation, which will also save much time.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" title="1"><span class="kw">stopCluster</span>(cl) <span class="co"># stop the cluster</span></a></code></pre></div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
